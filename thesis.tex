\documentclass[12pt]{report}
\usepackage[utf8]{inputenc}
\usepackage{graphicx, float}
\usepackage[a4paper, margin=2.5cm]{geometry}
\usepackage[skip=10pt plus1pt, indent=40pt]{parskip}
\usepackage{tocloft}
\usepackage{cite}
\usepackage{titlesec}
\usepackage{times}
\usepackage{natbib}
\usepackage{url}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{bookmark}
\usepackage{enumitem}


\renewcommand{\cftchapfont}{\bfseries}
\renewcommand{\cftchappagefont}{\bfseries}
\renewcommand{\cftchappresnum}{Chapter }
\renewcommand{\cftchapaftersnum}{:}
\renewcommand{\cftchapnumwidth}{6em}

\titleformat
{\chapter} % command to format
[block] % shape: hang, display, block, frame 
{\bfseries\Large \centering}  % format of label + chapter title
{CHAPTER\ \thechapter:} % label "Chapter 1:"
{1.5ex} % separation label - chapter title
{} % code before

\renewcommand{\baselinestretch}{1.5} 

\graphicspath{{img/}}

\begin{document}
\pagenumbering{roman}

\begin{center}
    \textbf{VIETNAM NATIONAL UNIVERSITY OF HO CHI MINH CITY}\\[6pt]
    \textbf{INTERNATIONAL UNIVERSITY}\\[6pt]
    \textbf{SCHOOL OF COMPUTER SCIENCE AND ENGINEERING}\\[50pt]
\end{center}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.3\textwidth]{iu-logo.png}\\[50pt]
\end{figure}

\begin{center}
    \textbf{\huge {Anomaly Detection in HDFS Logs}}
    \textbf{\huge {using Machine Learning Integrated with
            LLM-Based Mitigation}}\\[50pt]

    \textbf{By}\\
    \textbf{Nguyen Hoang Quan}\\[20pt]
    \textbf{The thesis submitted to School of Computer Science and Engineering in partial fulfillment of the requirements of the degree of Bachelor of Engineering of Information Technology}\\[80pt]

    \textbf{Ho Chi Minh, Viet Nam}\\
    \textbf{2025}
\end{center}

\newpage
\newgeometry{
    % Define the margin values:
    left=1.5in,
    right=1in,
    top=1.5in,
    bottom=1.5in,
    % Optional: Define the paper size if you haven't already
    % a4paper 
}


\begin{center}
    \textbf{\Large{Anomaly Detection in HDFS Logs using Machine         Learning Integrated
            with LLM-Based Mitigation
        }}\\[80pt]

\end{center}

\begin{flushright}
    \textnormal{APPROVED BY: \rule{6cm}{0.5pt}}
\end{flushright}


\newpage

\begin{center}
    \textbf{\large{ACKNOWLEDGEMENTS}}\\[20pt]
\end{center}

First and foremost, I would like to express my sincere gratitude to the School of Computer Science and Engineering for providing a supportive academic environment and the essential resources that made this thesis possible. \\[10pt]
I am deeply thankful to my advisor, Dr. Le Hai Duong, for his invaluable guidance, encouragement, and constructive feedback throughout the development of this thesis. His expertise and commitment has greatly enriched both my technical understanding and research direction. \\[10pt]
I would also like to extend my appreciation to all lecturers and staff members who have contributed to my academic journey with their instruction, support, and mentorship.
Special thanks go to my family and friends for their constant support, motivation, and understanding during the preparation of this work.
Lastly, I would like to acknowledge the developers and the researchers behind the resources for providing the foundation upon which this project was built. \\[10pt]
This thesis would not have been possible without the guidance, resources, and support from all of the above.


\newpage
\tableofcontents

\newpage
\listoftables

\newpage
\listoffigures

\newpage

\begin{center}
    \textbf{\large{ABSTRACT}}\\[20pt]
\end{center}

Anomaly detection is essential for managing today’s large-scale distributed systems, where system logs are a key resource for identifying unusual behavior. Traditionally, system operators relied on manual inspection methods such as keyword searches and rule-based matching. However, due to the massive volume and complexity of modern system logs, manual approaches are no longer practical. To tackle this, many automated log-based anomaly detection methods have been proposed. Still, developers often struggle to choose a suitable method, as there hasn't been a clear comparison of these approaches.

In this research, I will propose a solution to addresses the fundamental challenge of automated log analysis. Specially, the research tackles three interconnected problems: (1) automated parsing of diverse log formats into structured templates, (2) anomaly detection in high-volume log streams, and (3) generation of contextual, actionable recommendations for identified issues.

Previous research has established some foundational approaches including the algorithms for log parsing and machine learning techniques for anomaly detection. However, existing solutions typically focus on individual components rather than providing end-to-end integration. Most academic implementations lack production-ready deployment architectures, user-friendly interfaces, and the integration of modern Large Language Models (LLMs) for intelligent recommendations—creating a significant gap between theoretical algorithms and practical deployment. Therefore, this research is important since it close the gap between academic log analysis algorithms and production-ready systems.

Furthermore, the research establishes a framework for integrating emerging LLM capabilities into traditional system administration workflows, suggesting broader implications for AI-assisted DevOps practices. The findings indicate that intelligent automation of log analysis is not only technically feasible but can significantly enhance organizational capabilities in system reliability, security monitoring, and operational efficiency.

\newpage
\pagenumbering{arabic}
\setcounter{page}{1}

\chapter{INTRODUCTION}
\section{Background of the study}


In modern software systems, log files serve as critical sources of information
for system monitoring, debugging, troubleshooting, and security analysis. As applications or systems scale and increase its complexity,
the volume of generated log data gets bigger exponentially. Therefore, traditional manual approaches
for log analysis like manually examine through log files using basic tools such as grep or text
editors, has become less efficient and more defective \cite{author2023}. As the result,
it is becoming more difficult to detect anomalies within large scale system.

Over the year, a lot of automated log-based methods have been introduced to help detecting
system anomalies. These approaches usually require raw log preprocessing techniques, feature extraction
and machine-learning-based algorithms for processing vast amounts of
unstructured log data efficiently, identifying potential issues before they
escalate into critical failures. Recent advancements in natural language processing
and large language models (LLMs) have also increased the potential for
intelligent log analysis systems. However, despite these development, traditional machine-learning techniques and LLM-based approaches have yet to be efficiently integrated
into a single, cohesive log analysis framework.

This study focuses on leveraging existing machine learning approaches where log parsing and anomaly
detected are used, and augmenting them with large language model to provide  actionable insights and helpful recommendations.


\section{Problem Statement}

Despite the important role of log analysis that play in making the system more secure and reliable,
several significant challenges still persist in current practices:

\begin{itemize}
    \item \textit{Limited interpretability.} In log anomaly detection,
          the ability to interpret model's outputs is important for people who
          work as system administrators or analysts to effectively action to
          the alerts. They need to understand which log entries may be responsible
          for the detected abnormality. Yet, many traditional approaches only
          provide basic classified prediction without any explanation. As a result,
          engineers still have to perform further manual root cause analysis
          which in large-scale and complex systems becomes an very time-consuming
          and heavy task.

    \item \textit{Poor adaptability.} Many existing methods rely on a predefined
          set of log event templates during feature extraction phase (This phase will use the set of log event templates generated by
          log parsing to create numerical features for machine learning models \cite{SARHAN2024205}).
          However, as applications scale up and expand  in term of feature,
          new and unseen log events will definitely appear. Therefore, adapting to these
          changes require retraining models from scratch which make the systems become less practical
          in dynamic environments.

    \item \textit{Poor adaptability.}

\end{itemize}

\section{Objectives of the Study}

This study will perform the investigation on existing anomaly-detection
methodologies, compares the performance of different machine-learning
models, and develops a practical framework that integrates large language
models (LLMs) to automate and improve anomaly detection in real-world scenario.



\section{Limitations of the Study}


\chapter{LITERATURE REVIEW}

\section{Introduction to system log}

System logs, also known as event logs or audit trails, are automatically generated by
a computer system (its operating system, services, applications) that record events, changes and error that
occur inside that system. These log files serve an important role in monitoring system
health, diagnose failures, detecting anomalies, and ensure system security and compliance \cite{STUDIAWAN20191}.
System logs usually follow a semi-structured format which consist of several fields that capture
both the context and content of the event.\\[10pt]


\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{hdfs-log.png}
    \caption{This is the descriptive text that explains the figure.}
    \label{fig:hdfs-log} % The label for cross-referencing
\end{figure}

Figure 2.1 show a log snippet that was generated by HDFS DataNode, one of the core storage components in the Hadoop ecosystem
(a more detail explanation of this system will be provided below).
These log entries are created from the storage operations of the system such as
data writes, packet handling, and communication between DataNodes. A log entry typically follow a structure as follow:

\begin{itemize}
    \item \textit{Timestamp: 2016-10-02 12:24:52,337.} Indicates the exact moment when the system processed the event.

    \item \textit{Log level: INFO.} Shows that the entry reports normal operational activity

    \item \textit{Log message: org.apache.hadoop.hdfs.server.datanode.DataNode.clienttrace:...} Log messages provide a structured description of system behavior,
          capturing events, performance indicators. This is the most important part of a log entries and therefor become the
          foundation for monitoring, auditing and anomaly detection.

\end{itemize}

Given their important role in providing such essential information about the system, logs must be reliably collected,
centrally stored and appropriately maintained  to enable accurate monitoring, troubleshooting, and subsequent analytical processes.

\section{Traditional log analysis method}

Traditional log analysis have relied on two primary approaches (cite something): manual log inspection and rule-based pattern matching systems.
While these techniques are the foundation of the system administrators fields and troubleshooting, it were used during the time
when the system complexity and log volumes were much smaller than nowadays modern systems. Understanding the strengths and limitations of
these approaches will provide you a better context and insights of logs which will enhance your log analysis systems.


\subsection{Manual Log Inspection}

Manual log inspection is one of the earliest and most straightforward methods used by system
administrators to identify issues. In this approach, developers or administrators will
directly operate searching on raw log files using command-line tools such as \verb|grep| , \verb|tail|, \verb|less|,
to locate error logs or correlate timestamp of the incidents. While feasible for small log volumes, this method is very
time-consuming, highly error-prone and relies heavily on an operator’s familiarity with the system. Therefore, this approach
is no longer a feasible solution for detecting anomalies in large-scale systems which may produce millions of log entries
per hour. For instance, in 2013 the Alibaba Cloud system was reported to generate approximately 100 to
200 million log lines in one hour \citep{6410318}.

\subsection{Rule-Based Systems (Regex and Pattern Matching)}

To counter the limitations of manual log review, developers created rule-based system that used fixed rules, regular expressions (regex),
and predefined patterns to filter, parse, and identify specific events when a specification conditions are met.
For example, system operators can create rules to detect keywords such as "ERROR", "FAILED" or extract key information
from log entries. Rule-based methods offer some advantages: they are easy to implement and effective for detecting
obvious or recurring errors. Many traditional monitoring tools such as Nagios, Splunk (early versions)
\cite{splunk_field_extraction}, and Logstash \cite{logstash_grok},
they are heavily depend on popular pattern-matching techniques to filter, categorize, and index log data.

However, the effectiveness of rule-based approaches highly depend on the completeness and accuracy of the
hand-crafted predefined rules. It will become more defective in a constantly evolving environments where logs
format change frequently and new types of anomalies will appear which do not match the existing patterns. Maintaining
large sets of regex rules is also a labor-intensive action and require continuous manual updates on patterns which is
unsuitable for adaptive anomaly detection.



\section{Log parsing}


\section{Machine learning and deep learning for log anomaly detection}

As system continuously scaled and logs volumes grew bigger, manual or rule-based approaches is
no longer available. As a result, researchers began to adopt machine learning to automate
anomaly detection. These methods are created to enable it to learn the structures, numerical representations,
and patterns of logs without depending on predefined rules or templates. These approaches are often categorized as
supervised or unsupervised learning.

\subsection{Supervised learning}

\begin{enumerate}[label=\alph*.] % Sets the label format to (a), (b), (c)...
    \item Support Vector Machine (SVM)

          Support Vector Machine is one of the fundamental methods that proposed
          by Vapnik \cite{vapnik1998statistical} which is used for binary classification.
          The basic idea of this method is as follow. For nonlinear separable data, we
          can transform it to higher-dimensional space where the data becomes linearly separable.
          This allows the classifier to construct an optimal separating hyperplane between normal
          and anomalous log patterns. In log detection context, anomaly logs will be treated as negatives
          and normal one will be served as positive examples. But using this method for detecting
          anomalies often often suffers from class imbalance, where the positive examples is outnumber
          the negatives. As the result, the classifier will overfit the anomalous logs, which make
          it become weak in detecting new occur, unseen logs.

          \begin{figure}[H]
              \centering
              \includegraphics[width=0.7\textwidth]{svm.jpg}
              \caption{SVM classification}
              % \label{fig:my_image} % The label for cross-referencing
          \end{figure}

    \item Decision Tree (DS)

          Decision tree is one of the earliest machine learning approaches that apply to
          anomaly log detection and are defined by Quinlan \cite{quinlan2014c4} as "powerful
          and common tools for classification and prediction". This method recursively
          splitting data based on its features then create a tree-like structure where
          each leaf node represents a prediction class (normal or abnormal).
          When apply to log anomaly detection, we have to transform log entries into
          structured numerical features before feed it into decision tree algorithm.
          The applications of decision trees to log-based anomaly detection has been
          proposed in many research with promising results. He et al. \cite{7774521}
          did some experiments with anomaly logs in HDFS dataset using decision tree classifier and
          and prove the effectiveness of it. The approach not only achieve high accuracy
          but also provide interpretable rules that allows others to validate and refine
          them as they wish.
          In context of this research, decision tree served as a foundation machine
          learning algorithm for detecting anomalies in log data. The specific implementations
          and results of using this algorithm will be discussed more upon in subsequent sections.

          % \begin{enumerate}[label=\arabic*.]
          %     \item The first item in the list.
          %     \item The second item in the list.
          %     \item The third item in the list.
          % \end{enumerate}



    \item The final item summarizes the topic.
\end{enumerate}

\subsection{Unsupervised learning}

In many situation when anomaly data is not labeled or unavailable, the supervised
learning is thereby become impractical. As a result, unsupervised learing methods
have been adopted widely for log anomaly detection. These approaches aim to analyze
data without requiring labeled examples by discovering the characteristics of the
data itseft. This section will examine some popular unsupervised approaches that are
currently applied to log analysis.

\begin{enumerate}[label=\alph*.] % Sets the label format to (a), (b), (c)...

    \item Isolation Forrest

          Isolation Forrest is a machine learning algorithm that was introduced by Liu et al
          \cite{liu2012isolation} in 2012. His core principle of isolation forrest is that
          anomolies are more accessible to isolate than abnomalous points \cite{Longberg2024}.
          The algorithms will construct forrest of random binary trees to separate each
          data point. Each tree us built by randomly selecting a feature from the dataset
          and a split value within the feature's range, then repetitive split the
          data until it reach the maximum depth or the instance is isolated.

          \begin{figure}[H]
              \centering
              \includegraphics[width=1\textwidth]{isolation-forrest.png}
              \caption{Isolation Forest}
              % \label{fig:my_image} % The label for cross-referencing
          \end{figure}

          Figure 2.3 demonstrates the isolation capabilities of Isolation Forest algorithm.
          In the left, the data point is seperated with only one split, indicating a high anomaly score.
          On the other hand, data point on the right requires more splits,  suggesting it’s a
          nominal data point
    \item Principal Component Analysis (PCA)

          Principal Component Analysis is a common technique that widely used for dimensionality reduction
          \footnote{Dimensional reduction is the process of reducing the number of input variables
              (features) in a dataset keeping as much essential information as possible.}
          in a dataset. By doing so, PCA algorithm helps simplifying complex dataset, reducing
          the redundancy among features, and highlighting the most important patterns in the data
          \cite{jolliffe1990principal}. In anomaly detection, it first converts each log sequence
          into event count vector by counting how many time each type of log event appear in the
          sequence. Next, the PCA algorithm \cite{lee2006application,abdi2010principal}
          will capture the main patterns of normal log behavior then project those vectors to
          a learned space (also known as normal space). However, when a log sequence contains
          anomaly logs such as missing events or unusual log messages, PCA algorithm will mark
          it as abnormal behavior by calculating the Square Prediction Error (SPE) \cite{jackson1979control}
          , which measures the deviation from the learned normal patterns.

    \item K-Means Clustering



\end{enumerate}

- ml techniques: https://arxiv.org/pdf/2307.16714

\section{Large Language Models (LLMs) in Log Analysis}

Parsing with LLMs instead of templates:

% https://zeyang919.github.io/paper/LLMParser.pdf?utm_source=chatgpt.com

Explainability + anomaly detection:

\chapter{METHODOLOGIES}


\section{Overview}

This chapter describes the methodology that used to design, implement, and evaluate the
proposed log anomaly detection framework. The methodology follows a pipeline that begins with
data collection and preprocessing, then extract the features and using machine learning techniques
to detect anomolies. Large language models (LLMS) are also integrated to address the limitations
of the traditional approaches, giving more insights and contextual understanding of detected
anomolies. This chapter is organized to present each stage of a framework, from system arichiteture
and how data is prepared to model Implementation and evaluation.

\subsection{Research Approach}
In this study, I adopt a design-based experimental research approach that combines traditional
machine learning methods with large language model techniques. This approach will focus on
constructing a practical, user-friendly and production-ready log anomaly detection framework
by integrating proven traditional methods with LLM-based reasoning to addressing both the technical
and operational challenges of large-scale log analysis.

The methodology combines well-established components such as the Drain log parsing algorithms to
constructs structured log templates from raw log messages, Decision Tree or Isolation Forrest
machine learning models are compared to find the most effective one and implemented it as
detection instruments.

For data collection, this study relies primarily on secondary collection methods which uses public
and available log datasets like HDFS system logs or BGL logs dataset. There will be no primary data involving human
participants are collected. The data collection process includes log ingestion, parsing, feature extraction,
anomaly labeling (already prepared by experts), and preparation for model training and testing.

This study use a mixed-method of quantitative and qualitative analysis approaches. Quantitative analysis is utilized to evaluate the performance of detection models
using real statistics (e.g., detection rates and error rates) and comparison between models.
Furthermore, qualitative analysis is applied to the outputs that is generated by LLMs, focusing
on their ability to provide root cause explanations and mitigation suggestions.

Ethics are also considered in this study which relate to data usage and research integrity.
All datasets that I used are publicly available so it ensures no personal information is
exposed. Proper citation and acknowledgment of datasets, tools, and prior research are also maintained.
Additionally, this study is responsible for the LLM-generated outputs by put it as only suggestions
rather than automated direct action, and thereby preventing unintended operational impact.

\subsection{System Pipeline Overview}
The proposed framework follows a pipeline from transform raw systems logs into structured one and useful
recommendations through a sequence of stages. Figure \ref{fig:pipeline} illustrates the overall pipeline.

The pipeline begins with log preprocessing, where raw logs are parsed using the Drain algorithm. This
step will convert raw and unstructured log into sequence of structured events and extract event templates.

Structured log sequences will be the input for the processing step, where it will be transformed to
numerical representations and then fed to machine learning models for anomaly detection.

The final stage integrates large language models (LLMs) to enhance system interpretability. LLMs component
will perform semantic analysis based on detected anomalies and generate human-readable explanations about
root casues and useful suggestions. \\[10pt]

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{pipeline.png}
    \caption{System pipeline}
    \label{fig:pipeline}
    % \label{fig:my_image} % The label for cross-referencing
\end{figure}


\section{System Architecture and Design}
This section presents the system architecture and design of the proposed log anomaly detection framework.
We will focus on the structural composition of the system and also show their responsibilities, and interactions.
The architecture is designed to make the process of large-scale log data more efficiently while enabling to
integrate with traditional anomaly detection techniques and large language models (LLMs).

\subsection{Architectural Overview and Design Principles}

The proposed log analysis system follows a simple architecture but highlight the
practicality and ease of integration to support real-world problems. The systems is desgined around some
key principles:


\begin{enumerate}[label=\arabic*.]
    \item Asynchronous Processing

          The architecture apply asynchronous task processing to handle computationally heavy workload without
          affect user interface. Therefore the system can effective process large log files while also maintain
          good user interaction.

    \item Modular Service Design

          Each component in the system is designed as an independent module with clear responsibilities to maintain or test
          more easily, and also increase the ability of horizontally scaling of individual components.

    \item Data Layer Separation

          The system create a clear separation between metadata management and object storage that using
          MinIO for large-scale objects and PostgreSQL for logs structured metadata. This design optimizes
          the performance by addressing the data access pattern problem where PostgreSQL is suitable for
          structured queries and indexing whereas MinIO offer high throughput and cost efficiency for
          actual log storage.

    \item Multi-Stage Processing Pipeline

          In my log analysis system, I implemented a multi-stage pipeline which consists of parsing, anomaly detection,
          and intelligent analysis phases. This allows me to test and integrate different algorithms and models
          that is the most suitable for the system without disrupting the entire workflow.

\end{enumerate}

\subsection{High-Level System Architecture}

The system uses a layered, distributed architecture which is designed to support efficient log ingestion and
anomaly detection. Each layer is responsible for a distinct functionality ensuring the ease for development
and maintenance.

\begin{enumerate}[label=\arabic*.]

    \item Presentation layer

          This layer provides a user-friendly interface between end users and the log analysis system. It is a
          single-page application (SPA) that built on React framework, allowing users to upload
          log files, view processing status and final analyzed results. The system also develop
          authentication through JWT-based mechanism and role-based accesses for better security.

    \item API Gateway Layer

          The API gateway layer is responsible for create a communication between the frontend and backend.
          This layer expose REST API endpoints which will handle request routing, input validation and give back the
          responses by using FastAPI technologies.

    \item Service Layer

          The service layer hold the core business logic of the system. These services
          include authentication, handling log files, and managing model detection logic.
          and LLMs analysis.
          By separating functions into discreate services, the architecture allows each service to
          work independently and easy to change as you wish.

    \item Data Processing Layer

          Data processing is one of the most important steps in the entire workflow, so this layer
          is built very carefully. Raw log messages are parsed into structured one and extract event
          templates using Drain algorithm. Then using the structured logs to ingest to machine learning models
          and save as serialized file for real-time inference. Anomalies is then analyzed by LLMs
          to generate explanations about how it mark as anomaly and mitigation suggestions.

    \item Storage Layer

          The storage layer is designed to handle how log data will be stored and accessed effectively.
          MinIO is used to store actual raw log files that users upload to the server.
          I utilized this technology because its object storage allows storing and access large volume
          of data with high speed and low cost. Whereas PostgreSQL is chosen to manage structured metadata
          due to its ability to create complex structured queries. An in-memory cache (Redis) is also
          employed in this system to support fast access to data such as task queues.


    \item Task Management Layer

          To support asynchronous processing as I mentioned in section 3.2.1, the system also create a
          layer for task management. Each step such as parsing, anomaly detection, and LLM inference will
          be define as tasks and put to message queues. Celery workers will take tasks from queue and execute
          in the background, thereby parallel execution is made possible.

\end{enumerate}



\section{Dataset preparation}

The HDFS log data set is the most frequently used data set for anomaly detection methods and 
thus also the main focus point of this study. The logs were collected from the Hadoop Distributed
File System (HDFS), which runs on the Amazon EC2 platform. This system is designed to run on
commodity hardware and allows users to store and process large files. Each log event have one or more 
block identifiers which will enable grouping logs into sequence of events. And in fact, the sample
logs snippet show in Figure \ref{fig:hdfs-log} are taken from HDFS data set. The core idea behind 
the anomaly detection in this dataset is that some data blocks is fail to be processed by the 
system. When such failures happen, the blocks generate log events that differ from normal processing behavior.
Therefore, the entire sequence should be detected as anomalous \cite{xu2009detecting}.

The data was originally collected by Xu et al. from a production hadoop cluster comprising
more than 200 nodes. The dataset was labeled by domain experts to distinguish normal 
and anomalous execution flows. In this study the HDFS dataset version is taken from project
 Loghub \cite{zhu2023loghub}. The total lines of log messages in this dataset version is 
 11,175,629 but a close inspection of the dataset shows that approximately 22,000 lines are missing in comparison to the original data set for
unknown reasons. However, the remaining data still provides a sufficient sample for 
anomaly detection analysis and techniques evaluation.


\section{Log Parsing Methodology}




\section{Feature Extraction / Representation}
\section{Anomaly Detection Models}
\section{LLM Integration Method}





\chapter{IMPLEMETATIONS}
\section{Implementation Overview}
\section{Backend Implementation}
\subsection{FastAPI Application Architecture}
- Code snippets from src/main.py
- Router organization
- Dependency injection
- Database session management

\subsection{Database Layer Implementation}
- model diagram
- detail

\subsection{API Endpoints Implementation}


\section{Log Processing Pipeline}
\subsection{File Upload and Storage}
- MinIO client integration
- File validation logic
- Unique filename generation

\subsection{Asynchronous Processing with Celery}
- Celery configuration
- DatabaseTask base class
- Task retry logic
- Job status updates

\subsection{Drain Parser Integration}
- Parser service wrapper
- Temporary file handling
- Template extraction
- Output structuring

\subsection{Feature Extraction}
- Event counting
- Statistical features
- CSV conversion

\subsection{Decision Tree Anomaly Detection}
- Model training code
- Feature preparation
- Prediction pipeline
- Result storage

\section{LLM Integration}
\subsection{LLM Service Design}
- API client setup
- Context preparation

\subsection{LLM Service Design}
- System prompts
- User prompts with context
- Few-shot examples (if any)

% Recommendation Generation
\subsection{Recommendation Generation}
- Anomaly result processing
- LLM API calls
- Response Parsing

\section{Frontend Implementation}

\subsection{React Application Structure}
- Component organization
- Routing setup

\subsection{Key Components}



\chapter{CONCLUSION AND RECOMMENDATION}










\bibliographystyle{plain}
\bibliography{references}
\end{document}